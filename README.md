Este proyecto consiste en reescribir las funciones bÃ¡sicas de PyTorch desde cero, utilizando Ãºnicamente NumPy. El objetivo es aprender cÃ³mo funcionan internamente los tensores, la propagaciÃ³n, y el autograd, entre otros.

ğŸš€ CaracterÃ­sticas

ImplementaciÃ³n de tensores y operaciones bÃ¡sicas (suma, multiplicaciÃ³n, transposiciÃ³n, etc.) âœ…

Autograd: cÃ¡lculo manual del gradiente y backward propagation âœ…

Funciones de activaciÃ³n: ReLU, Sigmoid, Tanh, Softmax. âœ…

Funciones de pÃ©rdida: MSE, Cross-Entropy.âœ…

OptimizaciÃ³n con Gradient Descent, Adam.âœ…

Capas de Redes neuronales: Linear

Regularizacion: L1, L2, dropout 

Model serialization

Algoritmos de Machine Learning

Ejemplos prÃ¡cticos: regresiÃ³n lineal, clasificaciÃ³n simple.

ğŸ“‚ Estructura del Proyecto<br>
```
MiniTorch/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ nn/
â”‚ â”‚ â”œâ”€â”€ activations.py # Funciones de activaciÃ³n
â”‚ â”‚ â”œâ”€â”€ losses.py # Funciones de pÃ©rdida
â”‚ â”‚ â””â”€â”€ optimizers.py # Optimizadores (SGD)
â”‚ â”œâ”€â”€ tensor.py # Clase Tensor personalizada
â”‚ â””â”€â”€ operations.py # Operaciones bÃ¡sicas (suma, multiplicaciÃ³n, etc.)
â”œâ”€â”€ examples/ # Ejemplos de uso
â”‚ â””â”€â”€ linear_regression.py
â”œâ”€â”€ tests/
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```
ğŸ“ Ejemplo de Uso


ğŸ“Œ Como instalarlo

Clonar el repositorio:
```
git clone <https://github.com/ferxades12/MiniTorch>
cd <MiniTorch>
```
Crear un entorno virtual (opcional pero recomendado):

```
python -m venv venv
# En Linux/macOS
source venv/bin/activate
# En Windows
venv\Scripts\activate
```

Instalar las dependencias:
```
pip install -r requirements.txt
```
