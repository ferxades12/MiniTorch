This project consist of implementing Pytorch basic functionality, usin only NumPy (the other libs are for /test module)
The objective is to learn how neural networks work internally

ðŸš€ Roadmap

Tensor implementation and basic operations (sum, mul, transpose, etc.) âœ…

Autograd: manual grad calculation and backward propagation âœ…

Activation functions: ReLU, Sigmoid, Tanh, Softmax. âœ…

Loss functions: MSE, Cross-Entropy.âœ…

Optimizers: Gradient Descent, Adam.âœ…

Neural network layers: Linear, Sequential âœ…

Regularizations: L1, L2, dropout âœ…

Datasets, Dataloaders, random_split âœ…

Model serialization

ML Algorithms

Practical examples: xor classification âœ…

ðŸš¬:
DiseÃ±o meta + kernel (preparaciÃ³n para Rust)

IntegraciÃ³n de CUDA (CuPy)

Backend en Rust

Paralelismo en Rust

IntegraciÃ³n de CUDA en Rust


ðŸ“‚ Estructura del Proyecto<br>
```
MiniTorch/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ nn/
â”‚ â”‚ â”œâ”€â”€ activations.py # Activation functions
â”‚ â”‚ â”œâ”€â”€ losses.py # Loss functions
â”‚ â”‚ â”œâ”€â”€ functional.py # Non-class functions
â”‚ â”‚ â”œâ”€â”€ layers.py #nn layers
â”‚ â”‚ â”œâ”€â”€ regularizations.py
â”‚ â”‚ â””â”€â”€ optimizers.py # optimizers
â”‚ â”œâ”€â”€ utils/
â”‚ â”‚ â”œâ”€â”€ data.py # Dataloaders, etc.
â”‚ â”œâ”€â”€ tensor.py
â”‚ â””â”€â”€ operations.py
â”œâ”€â”€ examples/ # Ejemplos de uso
â”‚ â””â”€â”€ xor_classification.py
â”œâ”€â”€ tests/
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```


Cloning the repo:
```
git clone <https://github.com/ferxades12/MiniTorch>
cd <MiniTorch>
```
Creating venv (optional but recommended):

```
python -m venv venv
# En Linux/macOS
source venv/bin/activate
# En Windows
venv\Scripts\activate
```

Installing dependencies:
```
pip install -r requirements.txt
```
